{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9560502,"sourceType":"datasetVersion","datasetId":5826041}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"99fe7dc5","cell_type":"code","source":"# --- ENVIRONMENT & LIBRARY SETUP ---\nimport os\nimport sys\nimport pandas as pd\nimport time\nfrom tqdm.notebook import tqdm\nimport ast\n\nprint(\"=== VALIDATION DATA PREPROCESSING SETUP ===\")\nprint(f\"Python version: {sys.version.split()[0]}\")\nprint(f\"Working directory: {os.getcwd()}\")\n\n# Validate Kaggle environment\nassert '/kaggle/' in os.getcwd(), \"This notebook must run in Kaggle environment!\"\nprint(\"‚úì Confirmed running in Kaggle environment\")\n\n# Install required packages\nprint(\"Installing OpenAI package...\")\n!pip install -q openai\n\nfrom openai import OpenAI\nprint(\"‚úì Libraries imported successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T03:52:13.954605Z","iopub.execute_input":"2025-06-17T03:52:13.954961Z","iopub.status.idle":"2025-06-17T03:52:23.858193Z","shell.execute_reply.started":"2025-06-17T03:52:13.954905Z","shell.execute_reply":"2025-06-17T03:52:23.857088Z"}},"outputs":[{"name":"stdout","text":"=== VALIDATION DATA PREPROCESSING SETUP ===\nPython version: 3.11.11\nWorking directory: /kaggle/working\n‚úì Confirmed running in Kaggle environment\nInstalling OpenAI package...\n‚úì Libraries imported successfully\n","output_type":"stream"}],"execution_count":2},{"id":"88339589","cell_type":"code","source":"# --- API SETUP ---\nprint(\"Setting up OpenRouter API...\")\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"OPENROUTER_API_KEY\")\n    if api_key:\n        print(\"‚úì OpenRouter API key loaded from Kaggle Secrets\")\n    else:\n        raise ValueError(\"No API key found\")\nexcept Exception as e:\n    print(f\"‚ùå ERROR: Could not load API key: {e}\")\n    print(\"Please add OPENROUTER_API_KEY to Kaggle Secrets\")\n    raise\n\n# Initialize OpenRouter client\nopenrouter_client = OpenAI(\n    base_url=\"https://openrouter.ai/api/v1\",\n    api_key=api_key,\n)\n\nprint(\"‚úì OpenRouter client initialized\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T03:52:23.860129Z","iopub.execute_input":"2025-06-17T03:52:23.860534Z","iopub.status.idle":"2025-06-17T03:52:24.406899Z","shell.execute_reply.started":"2025-06-17T03:52:23.860510Z","shell.execute_reply":"2025-06-17T03:52:24.406140Z"}},"outputs":[{"name":"stdout","text":"Setting up OpenRouter API...\n‚úì OpenRouter API key loaded from Kaggle Secrets\n‚úì OpenRouter client initialized\n","output_type":"stream"}],"execution_count":3},{"id":"3cbe00f1","cell_type":"code","source":"# --- DATA LOADING ---\nprint(\"Loading validation data...\")\n\n# üß™ TESTING MODE - Set to True for small scale testing\nTESTING_MODE = False  # Change to False for full processing\nTEST_SAMPLE_SIZE = 10  # Number of samples for testing\n\n# üìä BATCH PROCESSING CONFIGURATION\n# Set these parameters to process specific ranges of data\nENABLE_RANGE_PROCESSING = False  # Set to True to enable range processing\nSTART_ROW = 0       # Start from this row (0-based index)\nEND_ROW = 500      # End at this row (exclusive, so this processes rows 0-999)\n\n# Find dataset\nkaggle_data_paths = [\n    \"/kaggle/input/data-of-multimodal-sarcasm-detection\",\n]\n\ndata_dir = None\nfor path in kaggle_data_paths:\n    if os.path.exists(path):\n        data_dir = path\n        print(f\"‚úì Dataset found at: {data_dir}\")\n        break\n\nif data_dir is None:\n    print(\"‚ùå ERROR: Dataset not found!\")\n    print(\"Please add the multimodal sarcasm detection dataset to this notebook\")\n    raise FileNotFoundError(\"Dataset not found\")\n\ndef load_validation_data(filepath):\n    \"\"\"Load validation data efficiently\"\"\"\n    records = []\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(f\"Validation file not found: {filepath}\")\n        \n    print(f\"Loading {filepath}...\")\n    with open(filepath, 'r', encoding='utf-8') as f:\n        for line_num, line in enumerate(f, 1):\n            try:\n                data_list = ast.literal_eval(line.strip())\n                if len(data_list) >= 3:\n                    records.append({\n                        'id': data_list[0], \n                        'text': data_list[1], \n                        'sarcasm': int(data_list[2])\n                    })\n            except (ValueError, SyntaxError, IndexError):\n                continue\n    \n    print(f\"‚úì Loaded {len(records)} validation records\")\n    return pd.DataFrame(records)\n\n# Load validation data - try both valid.txt and valid2.txt\nvalidation_files = ['valid2.txt']\nval_df = None\n\nfor filename in validation_files:\n    filepath = os.path.join(data_dir, 'text', filename)\n    if os.path.exists(filepath):\n        print(f\"üìÅ Found validation file: {filename}\")\n        val_df = load_validation_data(filepath)\n        break\n\nif val_df is None:\n    raise FileNotFoundError(\"No validation file found! Expected 'valid.txt' or 'valid2.txt'\")\n\n# üß™ Apply testing mode if enabled\nif TESTING_MODE:\n    print(f\"\\nüß™ TESTING MODE ENABLED\")\n    print(f\"Limiting data to {TEST_SAMPLE_SIZE} samples for testing\")\n    \n    # Take first TEST_SAMPLE_SIZE samples for quick testing\n    original_size = len(val_df)\n    val_df = val_df.head(TEST_SAMPLE_SIZE).copy()\n    \n    print(f\"Data reduced: {original_size} ‚Üí {len(val_df)} samples\")\n    print(\"‚ö†Ô∏è  Remember to set TESTING_MODE = False for full processing\")\nelif ENABLE_RANGE_PROCESSING:\n    print(f\"\\nüìä RANGE PROCESSING MODE ENABLED\")\n    original_size = len(val_df)\n    \n    # Handle negative END_ROW (means process till end)\n    actual_end_row = len(val_df) if END_ROW == -1 else min(END_ROW, len(val_df))\n    actual_start_row = max(0, START_ROW)\n    \n    print(f\"Processing rows {actual_start_row} to {actual_end_row-1}\")\n    print(f\"Total samples in this batch: {actual_end_row - actual_start_row}\")\n    \n    # Slice the dataframe to specified range\n    val_df = val_df.iloc[actual_start_row:actual_end_row].copy()\n    val_df.reset_index(drop=True, inplace=True)\n    \n    print(f\"Data filtered: {original_size} ‚Üí {len(val_df)} samples\")\n    print(f\"üìÅ Output will include batch info: batch_{actual_start_row}_{actual_end_row}\")\nelse:\n    print(f\"\\nüöÄ FULL PROCESSING MODE\")\n    print(f\"Processing all {len(val_df)} samples\")\n\n# Add image paths\nimage_folder = os.path.join(data_dir, 'dataset_image')\nval_df['image_path'] = val_df['id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))\n\n# Clean data with detailed logging\ninitial_count = len(val_df)\nprint(f\"\\nüßπ CLEANING DATA:\")\nprint(f\"Initial count: {initial_count}\")\n\n# Check for missing text\ntext_before = len(val_df)\nval_df.dropna(subset=['text'], inplace=True)\ntext_after = len(val_df)\ntext_dropped = text_before - text_after\nprint(f\"Dropped {text_dropped} rows with missing text ({text_dropped/text_before*100:.1f}%)\")\n\n# Convert sarcasm to int\nval_df['sarcasm'] = val_df['sarcasm'].astype(int)\n\n# Check for missing images\nimage_before = len(val_df)\nmissing_images = []\nfor idx, row in val_df.iterrows():\n    if not os.path.exists(row['image_path']):\n        missing_images.append(row['id'])\n\nif missing_images:\n    print(f\"Found {len(missing_images)} missing image files\")\n    print(f\"Sample missing images: {missing_images[:5]}...\")\n    \nval_df.drop(val_df[~val_df['image_path'].apply(os.path.exists)].index, inplace=True)\nimage_after = len(val_df)\nimage_dropped = image_before - image_after\nprint(f\"Dropped {image_dropped} rows with missing images ({image_dropped/image_before*100:.1f}%)\")\n\nfinal_count = len(val_df)\n\nprint(f\"\\nData cleaned: {initial_count} ‚Üí {final_count} samples\")\nprint(f\"Sarcastic: {len(val_df[val_df['sarcasm']==1])}\")\nprint(f\"Non-sarcastic: {len(val_df[val_df['sarcasm']==0])}\")\n\n# Show estimated time based on current data size\nestimated_time_minutes = (final_count * 8) / 60\nif estimated_time_minutes < 60:\n    print(f\"‚è±Ô∏è  Estimated processing time: {estimated_time_minutes:.1f} minutes\")\nelse:\n    print(f\"‚è±Ô∏è  Estimated processing time: {estimated_time_minutes/60:.1f} hours\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T03:52:24.407730Z","iopub.execute_input":"2025-06-17T03:52:24.408014Z","iopub.status.idle":"2025-06-17T03:52:24.557700Z","shell.execute_reply.started":"2025-06-17T03:52:24.407990Z","shell.execute_reply":"2025-06-17T03:52:24.556689Z"}},"outputs":[{"name":"stdout","text":"Loading validation data...\n‚úì Dataset found at: /kaggle/input/data-of-multimodal-sarcasm-detection\nüìÅ Found validation file: valid2.txt\nLoading /kaggle/input/data-of-multimodal-sarcasm-detection/text/valid2.txt...\n‚úì Loaded 2410 validation records\n\nüß™ TESTING MODE ENABLED\nLimiting data to 10 samples for testing\nData reduced: 2410 ‚Üí 10 samples\n‚ö†Ô∏è  Remember to set TESTING_MODE = False for full processing\n\nüßπ CLEANING DATA:\nInitial count: 10\nDropped 0 rows with missing text (0.0%)\nDropped 0 rows with missing images (0.0%)\n\nData cleaned: 10 ‚Üí 10 samples\nSarcastic: 10\nNon-sarcastic: 0\n‚è±Ô∏è  Estimated processing time: 1.3 minutes\n","output_type":"stream"}],"execution_count":4},{"id":"fae48307","cell_type":"code","source":"# --- LLM PREPROCESSING FUNCTION ---\ndef preprocess_with_llm(text):\n    \"\"\"Preprocess text with LLM\"\"\"\n    if not isinstance(text, str) or not text.strip():\n        return \"\"\n        \n    try:\n        completion = openrouter_client.chat.completions.create(\n            model=\"mistralai/mistral-nemo\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are an expert text preprocessor for a machine learning model. Your task is to clean and standardize tweet text. Follow these rules strictly:\\n1. Correct typos and grammatical errors.\\n2. Expand internet slang and abbreviations into standard English (e.g., 'lol' becomes 'laughing out loud').\\n3. Convert hashtags into meaningful phrases (e.g., '#nosleep' becomes 'no sleep').\\n4. Remove any URLs and mentions like '<user>'.\\n5. CRITICALLY IMPORTANT: Preserve the original tone, especially sarcasm or irony. Do not change the underlying meaning.\\n6. Your output must ONLY be the final cleaned text, with no extra explanations or chat.\"},\n                {\"role\": \"user\", \"content\": f\"Please preprocess the following tweet: \\\"<user> OMG u kno what i mean?! today is going to be awesome! #nosleep #bestdayever\\\"\"},\n                {\"role\": \"assistant\", \"content\": \"Oh my god, you know what I mean?! Today is going to be awesome! No sleep. Best day ever.\"},\n                {\"role\": \"user\", \"content\": f\"Please preprocess the following tweet: \\\"{text}\\\"\"}\n            ],\n            temperature=0.1,\n            max_tokens=150,\n        )\n        cleaned_text = completion.choices[0].message.content.strip()\n        time.sleep(4)  # Rate limiting - 8 seconds between requests\n        return cleaned_text\n    except Exception as e:\n        if \"429\" in str(e):  # Rate limit\n            print(f\"Rate limit hit, waiting 60 seconds...\")\n            time.sleep(60)\n            return text  # Return original on rate limit\n        else:\n            print(f\"Error processing text: {e}\")\n            return text  # Return original on other errors\n\nprint(\"‚úì LLM preprocessing function ready\")\n\n# --- OUTPUT FILE SETUP ---\n\n# Set output filenames based on mode\nif TESTING_MODE:\n    OUTPUT_CSV = \"validation_preprocessed_testing.csv\"\n    print(f\"üß™ Testing mode: Output will be saved to '{OUTPUT_CSV}'\")\nelse:\n    OUTPUT_CSV = \"validation_preprocessed.csv\"\n    print(f\"üöÄ Full mode: Final output will be saved to '{OUTPUT_CSV}'\")\n\nprint(f\"\\nOutput file: {OUTPUT_CSV}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T03:52:24.558771Z","iopub.execute_input":"2025-06-17T03:52:24.559278Z","iopub.status.idle":"2025-06-17T03:52:24.569589Z","shell.execute_reply.started":"2025-06-17T03:52:24.559248Z","shell.execute_reply":"2025-06-17T03:52:24.568501Z"}},"outputs":[{"name":"stdout","text":"‚úì LLM preprocessing function ready\nüß™ Testing mode: Output will be saved to 'validation_preprocessed_testing.csv'\n\nOutput file: validation_preprocessed_testing.csv\n","output_type":"stream"}],"execution_count":5},{"id":"a6d5985f","cell_type":"code","source":"# --- BATCH PROCESSING WITH RESUME CAPABILITY ---\n\n# Set output filename and save frequency based on mode\nif TESTING_MODE:\n    output_file = \"/kaggle/working/validation_processed_TEST.csv\"\n    save_frequency = 5  # Save every 5 samples for testing\n    print(f\"üß™ Testing mode: Output will be saved as validation_processed_TEST.csv\")\nelif ENABLE_RANGE_PROCESSING:\n    # Create filename with batch info\n    actual_end_row = len(val_df) + START_ROW if END_ROW == -1 else END_ROW\n    batch_name = f\"batch_{START_ROW}_{actual_end_row}\"\n    output_file = f\"/kaggle/working/validation_processed_{batch_name}.csv\"\n    save_frequency = 20  # Save every 20 samples for batch processing\n    print(f\"üìä Range mode: Output will be saved as validation_processed_{batch_name}.csv\")\n    print(f\"üìÅ Processing samples {START_ROW} to {actual_end_row-1}\")\nelse:\n    output_file = \"/kaggle/working/validation_processed_complete.csv\"\n    save_frequency = 20  # Save every 20 samples for full processing\n    print(f\"üöÄ Full mode: Output will be saved as validation_processed_complete.csv\")\n\n# Check for existing progress\nstart_idx = 0\nprocessed_data = []\n\n# For full mode, check if we can resume from testing mode results\nif not TESTING_MODE:\n    test_file = \"/kaggle/working/validation_processed_TEST.csv\"\n    if os.path.exists(test_file) and not os.path.exists(output_file):\n        try:\n            test_df = pd.read_csv(test_file)\n            if 'processed_text' in test_df.columns and len(test_df) > 0:\n                print(f\"üîÑ Found testing results ({len(test_df)} samples)\")\n                print(f\"üìã These will be included in full processing to avoid reprocessing\")\n                processed_data = test_df.to_dict('records')\n                start_idx = len(processed_data)\n        except Exception as e:\n            print(f\"Could not load test results: {e}\")\n\n# Check for existing progress in main output file\nif os.path.exists(output_file):\n    try:\n        existing_df = pd.read_csv(output_file)\n        if 'processed_text' in existing_df.columns:\n            # If we don't have any data yet, load from existing file\n            if len(processed_data) == 0:\n                processed_data = existing_df.to_dict('records')\n                start_idx = len(processed_data)\n            # If existing file has more data than our current progress, use it\n            elif len(existing_df) > len(processed_data):\n                processed_data = existing_df.to_dict('records')\n                start_idx = len(processed_data)\n            \n            print(f\"‚úì Resuming from index {start_idx} ({start_idx}/{len(val_df)} completed)\")\n        else:\n            print(\"Existing file found but invalid format, starting fresh\")\n    except Exception as e:\n        print(f\"Error reading existing file: {e}, starting fresh\")\n\nif start_idx == 0:\n    print(\"Starting fresh preprocessing...\")\nelif start_idx > 0 and not TESTING_MODE:\n    print(f\"üìà Will continue processing from sample {start_idx+1} to {len(val_df)}\")\n\n# Calculate remaining work\nremaining_samples = len(val_df) - start_idx\nestimated_time_minutes = (remaining_samples * 8) / 60  # 8 seconds per sample\nprint(f\"Remaining samples: {remaining_samples}\")\n\nif estimated_time_minutes < 60:\n    print(f\"Estimated time: {estimated_time_minutes:.1f} minutes\")\nelse:\n    print(f\"Estimated time: {estimated_time_minutes/60:.1f} hours\")\n\nif remaining_samples == 0:\n    print(\"‚úì All data already processed!\")\nelse:\n    # Process remaining data\n    total_processed = len(processed_data)\n    start_time = time.time()\n    \n    for i in tqdm(range(start_idx, len(val_df)), desc=\"Processing validation data\"):\n        row = val_df.iloc[i]\n        \n        # Create processed row\n        processed_row = {\n            'id': row['id'],\n            'text': row['text'],\n            'sarcasm': row['sarcasm'],\n            'image_path': row['image_path']\n        }\n        \n        # Process with LLM\n        try:\n            processed_text = preprocess_with_llm(row['text'])\n            processed_row['processed_text'] = processed_text\n        except Exception as e:\n            print(f\"Failed to process sample {i}: {e}\")\n            processed_row['processed_text'] = row['text']  # Use original\n        \n        processed_data.append(processed_row)\n        total_processed += 1\n        \n        # Progress update - UBAH ANGKA INI UNTUK MENGATUR FREKUENSI PROGRESS\n        if total_processed % 10 == 0:  # ‚Üê Ganti 10 dengan angka lain (50, 100, dll)\n            elapsed = time.time() - start_time\n            rate = total_processed / elapsed if elapsed > 0 else 0\n            remaining = len(val_df) - len(processed_data)\n            eta = remaining / rate if rate > 0 else 0\n            print(f\"‚úì Processed {total_processed}/{len(val_df)} | Rate: {rate:.1f}/min | ETA: {eta/60:.1f}min\")\n        \n        # Save progress periodically\n        if (i + 1) % save_frequency == 0:\n            temp_df = pd.DataFrame(processed_data)\n            temp_df.to_csv(output_file, index=False)\n            print(f\"\\nüíæ Progress saved: {len(processed_data)}/{len(val_df)} samples\")\n            \n            remaining_after_save = len(val_df) - len(processed_data)\n            time_remaining_minutes = (remaining_after_save * 8) / 60\n            \n            if time_remaining_minutes < 60:\n                print(f\"‚è±Ô∏è  Estimated remaining: {time_remaining_minutes:.1f} minutes\")\n            else:\n                print(f\"‚è±Ô∏è  Estimated remaining: {time_remaining_minutes/60:.1f} hours\")\n\n# Final save\nfinal_df = pd.DataFrame(processed_data)\nfinal_df.to_csv(output_file, index=False)\n\nelapsed_time = time.time() - start_time\nprint(f\"\\nüéâ PREPROCESSING COMPLETED!\")\nprint(f\"üìÑ Output file: {output_file}\")\nprint(f\"üìä Total samples processed: {len(final_df)}\")\nprint(f\"üíæ File size: {os.path.getsize(output_file) / (1024*1024):.2f} MB\")\nprint(f\"‚è∞ Total time: {elapsed_time/60:.1f} minutes\")\nprint(f\"üöÄ Average rate: {len(final_df)/(elapsed_time/60):.1f} samples/minute\")\n\nif TESTING_MODE:\n    print(f\"\\nüß™ TESTING COMPLETE!\")\n    print(f\"‚úÖ CSV file created successfully with {len(final_df)} samples\")\n    print(f\"üîÑ To process full data: Set TESTING_MODE = False in cell 4\")\n    print(f\"üìã Your test results will be automatically included in full processing!\")\nelif ENABLE_RANGE_PROCESSING:\n    actual_end_row = len(final_df) + START_ROW\n    print(f\"\\nüìä BATCH PROCESSING COMPLETE!\")\n    print(f\"‚úÖ Batch {START_ROW}-{actual_end_row-1} processed successfully\")\n    print(f\"üìÅ File: validation_processed_batch_{START_ROW}_{actual_end_row}.csv\")\n    print(f\"üîÑ To process next batch: Update START_ROW and END_ROW in cell 4\")\n    print(f\"üìã After all batches: Use merge script to combine all batch files\")\n    print(f\"\\nüí° Next batch suggestion:\")\n    print(f\"   START_ROW = {actual_end_row}\")\n    print(f\"   END_ROW = {actual_end_row + 1000}  # or -1 for remaining data\")\nelse:\n    print(f\"\\n‚úÖ Ready for download and use in training notebook!\")\n\n# Display sample results\nprint(f\"\\nüìã Sample of processed data:\")\nprint(final_df[['id', 'sarcasm', 'text', 'processed_text']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T03:52:24.572131Z","iopub.execute_input":"2025-06-17T03:52:24.572430Z","iopub.status.idle":"2025-06-17T03:54:00.146086Z","shell.execute_reply.started":"2025-06-17T03:52:24.572407Z","shell.execute_reply":"2025-06-17T03:54:00.145207Z"}},"outputs":[{"name":"stdout","text":"üß™ Testing mode: Output will be saved as validation_processed_TEST.csv\nStarting fresh preprocessing...\nRemaining samples: 10\nEstimated time: 1.3 minutes\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing validation data:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"184203dcbf024f8c9433b714efa7e641"}},"metadata":{}},{"name":"stdout","text":"\nüíæ Progress saved: 5/10 samples\n‚è±Ô∏è  Estimated remaining: 0.7 minutes\n‚úì Processed 10/10 | Rate: 0.1/min | ETA: 0.0min\n\nüíæ Progress saved: 10/10 samples\n‚è±Ô∏è  Estimated remaining: 0.0 minutes\n\nüéâ PREPROCESSING COMPLETED!\nüìÑ Output file: /kaggle/working/validation_processed_TEST.csv\nüìä Total samples processed: 10\nüíæ File size: 0.00 MB\n‚è∞ Total time: 1.6 minutes\nüöÄ Average rate: 6.3 samples/minute\n\nüß™ TESTING COMPLETE!\n‚úÖ CSV file created successfully with 10 samples\nüîÑ To process full data: Set TESTING_MODE = False in cell 4\nüìã Your test results will be automatically included in full processing!\n\nüìã Sample of processed data:\n                   id  sarcasm  \\\n0  915657464401580032        1   \n1  854678856724340736        1   \n2  904892917277274112        1   \n3  855466461296504832        1   \n4  927373534652805120        1   \n\n                                                text  \\\n0  whew ... that extra <num> miles today to the g...   \n1  \" oh , good . now no one will know we 're here...   \n2  how much of it you think is true ? has this be...   \n3  <user> finally found proof that the earth is f...   \n4  many ways to overcome tension & fear but nothi...   \n\n                                      processed_text  \n0  Whew... That extra 5 miles today to the grocer...  \n1         Oh, good. Now no one will know we're here.  \n2  How much of it do you think is true? Has this ...  \n3                                      Earth is flat  \n4  Many ways to overcome tension and fear, but no...  \n","output_type":"stream"}],"execution_count":6},{"id":"5cf6b8bd","cell_type":"code","source":"# --- VERIFICATION & SUMMARY ---\nprint(\"=== FINAL VERIFICATION ===\")\n\n# Load and verify final file\nfinal_df = pd.read_csv(output_file)\n\nprint(f\"üìä Dataset Summary:\")\nprint(f\"   Total samples: {len(final_df)}\")\nprint(f\"   Sarcastic: {len(final_df[final_df['sarcasm']==1])}\")\nprint(f\"   Non-sarcastic: {len(final_df[final_df['sarcasm']==0])}\")\nprint(f\"   Missing processed_text: {final_df['processed_text'].isna().sum()}\")\n\n# Show sample of processed data\nprint(f\"\\nüìù Sample of processed data:\")\nfor i in range(min(3, len(final_df))):\n    row = final_df.iloc[i]\n    print(f\"\\nSample {i+1}:\")\n    print(f\"  Original:  {row['text'][:100]}...\")\n    print(f\"  Processed: {row['processed_text'][:100]}...\")\n    print(f\"  Label: {row['sarcasm']}\")\n\nprint(f\"\\nüéØ MISSION ACCOMPLISHED - PERSON 2 TASK COMPLETE!\")\nprint(f\"üì§ Download the file and share with team for training phase\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T03:54:00.149373Z","iopub.execute_input":"2025-06-17T03:54:00.149598Z","iopub.status.idle":"2025-06-17T03:54:00.165088Z","shell.execute_reply.started":"2025-06-17T03:54:00.149569Z","shell.execute_reply":"2025-06-17T03:54:00.164113Z"}},"outputs":[{"name":"stdout","text":"=== FINAL VERIFICATION ===\nüìä Dataset Summary:\n   Total samples: 10\n   Sarcastic: 10\n   Non-sarcastic: 0\n   Missing processed_text: 0\n\nüìù Sample of processed data:\n\nSample 1:\n  Original:  whew ... that extra <num> miles today to the grocery store & back wore me out .  so why are you usin...\n  Processed: Whew... That extra 5 miles today to the grocery store and back wore me out. So why are you using a c...\n  Label: 1\n\nSample 2:\n  Original:  \" oh , good . now no one will know we 're here . \" # remingtonsteele # piercebrosnan  # delivery # j...\n  Processed: Oh, good. Now no one will know we're here....\n  Label: 1\n\nSample 3:\n  Original:  how much of it you think is true ? has this become real ? well today 's food for brain . # thoughts ...\n  Processed: How much of it do you think is true? Has this become real? Well, today's food for thought....\n  Label: 1\n\nüéØ MISSION ACCOMPLISHED - PERSON 2 TASK COMPLETE!\nüì§ Download the file and share with team for training phase\n","output_type":"stream"}],"execution_count":7}]}