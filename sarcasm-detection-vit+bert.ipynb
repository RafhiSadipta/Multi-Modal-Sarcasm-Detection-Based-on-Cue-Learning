{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9560502,"sourceType":"datasetVersion","datasetId":5826041}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Instalasi library yang diperlukan dari Hugging Face\n!pip install -q transformers ftfy regex accelerate\n!pip install --upgrade -q transformers\n\n# Impor library standar dan dari Hugging Face\nimport os\nimport torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nfrom transformers import BertTokenizer, ViTImageProcessor, ViTModel, BertModel\nfrom torch.optim import AdamW\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport ast\n\n# Cek ketersediaan GPU\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-16T14:57:45.359874Z","iopub.execute_input":"2025-06-16T14:57:45.360141Z","iopub.status.idle":"2025-06-16T15:01:01.374762Z","shell.execute_reply.started":"2025-06-16T14:57:45.360116Z","shell.execute_reply":"2025-06-16T15:01:01.373581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path ke direktori dataset di Kaggle\ndata_dir = \"/kaggle/input/data-of-multimodal-sarcasm-detection\"\n\n# Fungsi untuk memuat data dari file .txt\ndef load_data_from_txt(filepath):\n    records = []\n    with open(filepath, 'r', encoding='utf-8') as f:\n        for line in f:\n            try:\n                # Menggunakan ast.literal_eval untuk mengubah string menjadi list\n                data_list = ast.literal_eval(line.strip())\n                tweet_id = data_list[0]\n                text = data_list[1]\n                label = int(data_list[2])\n                records.append({'id': tweet_id, 'text': text, 'sarcasm': label})\n            except (ValueError, SyntaxError):\n                continue\n    return pd.DataFrame(records)\n\n# Memuat data dari masing-masing file\ntrain_df = load_data_from_txt(os.path.join(data_dir, 'text', 'train.txt'))\nval_df = load_data_from_txt(os.path.join(data_dir, 'text', 'valid2.txt'))\ntest_df = load_data_from_txt(os.path.join(data_dir, 'text', 'test2.txt'))\n\n# Membuat path lengkap untuk setiap gambar\nimage_folder = os.path.join(data_dir, 'dataset_image')\ntrain_df['image_path'] = train_df['id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))\nval_df['image_path'] = val_df['id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))\ntest_df['image_path'] = test_df['id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))\n\n# Memastikan hanya baris dengan gambar yang ada yang diproses\ntrain_df = train_df[train_df['image_path'].apply(os.path.exists)].dropna()\nval_df = val_df[val_df['image_path'].apply(os.path.exists)].dropna()\ntest_df = test_df[test_df['image_path'].apply(os.path.exists)].dropna()\n\n# Mengubah tipe data kolom 'sarcasm' menjadi integer\ntrain_df['sarcasm'] = train_df['sarcasm'].astype(int)\nval_df['sarcasm'] = val_df['sarcasm'].astype(int)\ntest_df['sarcasm'] = test_df['sarcasm'].astype(int)\n\n# Mengubah skenario menjadi 16-shot untuk data latih\nsarcastic_samples = train_df[train_df['sarcasm'] == 1].sample(n=16, random_state=42)\nnon_sarcastic_samples = train_df[train_df['sarcasm'] == 0].sample(n=16, random_state=42)\ntrain_df_16shot = pd.concat([sarcastic_samples, non_sarcastic_samples])\n\nprint(f\"Ukuran data latih (16-shot): {len(train_df_16shot)}\")\nprint(f\"Ukuran data validasi: {len(val_df)}\")\nprint(f\"Ukuran data uji: {len(test_df)}\")\n\ntrain_df_16shot.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T15:01:01.377071Z","iopub.execute_input":"2025-06-16T15:01:01.377788Z","iopub.status.idle":"2025-06-16T15:02:28.131008Z","shell.execute_reply.started":"2025-06-16T15:01:01.377756Z","shell.execute_reply":"2025-06-16T15:02:28.129997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SarcasmViTBertDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, image_processor):\n        self.dataframe = dataframe\n        self.tokenizer = tokenizer\n        self.image_processor = image_processor\n        self.texts = dataframe['text'].tolist()\n        self.image_paths = dataframe['image_path'].tolist()\n        self.labels = dataframe['sarcasm'].tolist()\n        self.max_length = 77 # Panjang token maksimal, sama seperti sebelumnya\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        image_path = self.image_paths[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n\n        # Memproses teks dengan BERT Tokenizer\n        tokenized_text = self.tokenizer(\n            text,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n\n        # Memproses gambar dengan ViT Image Processor\n        image = Image.open(image_path).convert(\"RGB\")\n        processed_image = self.image_processor(\n            images=image,\n            return_tensors=\"pt\"\n        )\n\n        return {\n            'input_ids': tokenized_text['input_ids'].squeeze(0),\n            'attention_mask': tokenized_text['attention_mask'].squeeze(0),\n            'pixel_values': processed_image['pixel_values'].squeeze(0),\n            'labels': label\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T15:02:28.131942Z","iopub.execute_input":"2025-06-16T15:02:28.132234Z","iopub.status.idle":"2025-06-16T15:02:28.140281Z","shell.execute_reply.started":"2025-06-16T15:02:28.132205Z","shell.execute_reply":"2025-06-16T15:02:28.139194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ViTBertSarcasmModel(nn.Module):\n    def __init__(self, vit_model_name=\"google/vit-base-patch16-224-in21k\", bert_model_name=\"bert-base-uncased\", fine_tune_pretrained=False):\n        super().__init__()\n        # 1. Model Vision (ViT)\n        self.vit = ViTModel.from_pretrained(vit_model_name)\n        # 2. Model Teks (BERT)\n        self.bert = BertModel.from_pretrained(bert_model_name)\n\n        # Bekukan (freeze) parameter model pre-trained jika tidak ingin di-fine-tune\n        if not fine_tune_pretrained:\n            for param in self.vit.parameters():\n                param.requires_grad = False\n            for param in self.bert.parameters():\n                param.requires_grad = False\n\n        # 3. Lapisan Klasifikasi\n        # Ukuran fitur gabungan: 768 (dari ViT) + 768 (dari BERT) = 1536\n        fusion_dim = self.vit.config.hidden_size + self.bert.config.hidden_size\n        self.classifier = nn.Sequential(\n            nn.Linear(fusion_dim, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 2) # Output 2 kelas: non-sarkasme, sarkasme\n        )\n\n    def forward(self, input_ids, attention_mask, pixel_values):\n        # Proses gambar melalui ViT\n        # Output ViT memiliki 'last_hidden_state' dan 'pooler_output'\n        # Kita ambil representasi [CLS] token dari gambar\n        vision_outputs = self.vit(pixel_values=pixel_values)\n        image_features = vision_outputs.last_hidden_state[:, 0, :] # Ambil [CLS] token\n\n        # Proses teks melalui BERT\n        # Output BERT juga memiliki 'last_hidden_state' dan 'pooler_output'\n        # 'pooler_output' adalah representasi [CLS] token yang sudah diproses lebih lanjut\n        text_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        text_features = text_outputs.pooler_output\n\n        # Gabungkan (concatenate) fitur dari kedua modalitas\n        combined_features = torch.cat((image_features, text_features), dim=1)\n\n        # Lewatkan fitur gabungan ke classifier\n        logits = self.classifier(combined_features)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T15:02:28.141131Z","iopub.execute_input":"2025-06-16T15:02:28.141497Z","iopub.status.idle":"2025-06-16T15:02:28.186956Z","shell.execute_reply.started":"2025-06-16T15:02:28.141467Z","shell.execute_reply":"2025-06-16T15:02:28.185936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tentukan nama model pre-trained yang akan digunakan\nVIT_MODEL = 'google/vit-base-patch16-224-in21k'\nBERT_MODEL = 'bert-base-uncased'\n\n# Inisialisasi tokenizer dan image processor\ntokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\nimage_processor = ViTImageProcessor.from_pretrained(VIT_MODEL)\n\n# Inisialisasi model dan pindahkan ke GPU\nmodel = ViTBertSarcasmModel(vit_model_name=VIT_MODEL, bert_model_name=BERT_MODEL).to(device)\n\n# Membuat instance Dataset dan DataLoader\ntrain_dataset = SarcasmViTBertDataset(train_df_16shot, tokenizer, image_processor)\nval_dataset = SarcasmViTBertDataset(val_df, tokenizer, image_processor)\ntest_dataset = SarcasmViTBertDataset(test_df, tokenizer, image_processor)\n\n# Ukuran batch\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n\n# Optimizer (Hanya akan melatih parameter classifier jika model pre-trained di-freeze)\noptimizer = AdamW(model.parameters(), lr=5e-5) # Learning rate umum untuk fine-tuning\ncriterion = nn.CrossEntropyLoss()\n\nprint(\"Inisialisasi selesai. Siap untuk melatih model.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T15:05:28.242079Z","iopub.execute_input":"2025-06-16T15:05:28.242593Z","iopub.status.idle":"2025-06-16T15:05:28.915655Z","shell.execute_reply.started":"2025-06-16T15:05:28.242552Z","shell.execute_reply":"2025-06-16T15:05:28.914072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sel 6: Training and Evaluation Loop\nfrom sklearn.metrics import accuracy_score, f1_score\n\nnum_epochs = 100 # Mengurangi jumlah epoch untuk contoh, bisa disesuaikan\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n\n    for batch in progress_bar:\n        # Pindahkan data batch ke device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        pixel_values = batch['pixel_values'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Forward pass\n        outputs = model(input_ids, attention_mask, pixel_values)\n        loss = criterion(outputs, labels)\n\n        # Backward pass dan optimisasi\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        progress_bar.set_postfix({'loss': loss.item()})\n\n    avg_train_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1} | Average Training Loss: {avg_train_loss:.4f}\")\n\n    # --- Evaluasi pada data validasi ---\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            pixel_values = batch['pixel_values'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask, pixel_values)\n            preds = torch.argmax(outputs, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds)\n    print(f\"Validation Accuracy: {acc:.4f} | Validation F1-Score: {f1:.4f}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T15:06:54.080825Z","iopub.execute_input":"2025-06-16T15:06:54.081212Z","execution_failed":"2025-06-16T15:49:44.759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sel 7: Final Evaluation on Test Set & Saving\nprint(\"\\n--- EVALUASI AKHIR PADA TEST SET ---\")\nmodel.eval()\nall_test_preds = []\nall_test_labels = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Testing on Test Set\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        pixel_values = batch['pixel_values'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask, pixel_values)\n        preds = torch.argmax(outputs, dim=1)\n\n        all_test_preds.extend(preds.cpu().numpy())\n        all_test_labels.extend(labels.cpu().numpy())\n\nfinal_acc = accuracy_score(all_test_labels, all_test_preds)\nfinal_f1 = f1_score(all_test_labels, all_test_preds)\n\nprint(f\"\\nFinal Test Accuracy (ACC): {final_acc:.4f}\")\nprint(f\"Final Test F1-Score: {final_f1:.4f}\")\n\n# Simpan hasil ke CSV\nresults_df = test_df.copy()\nresults_df['predicted_sarcasm'] = all_test_preds\nresults_df['true_sarcasm'] = all_test_labels\nresults_df['final_accuracy'] = final_acc\nresults_df['final_f1_score'] = final_f1\ncsv_filename = 'test_results_vit_bert.csv'\nresults_df.to_csv(csv_filename, index=False)\nprint(f\"\\nHasil tes berhasil disimpan ke file: {csv_filename}\")\n\n# Simpan model\nmodel_filename = 'vit_bert_sarcasm_model.pth'\ntorch.save(model.state_dict(), model_filename)\nprint(f\"Model berhasil disimpan ke file: {model_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T15:02:35.850707Z","iopub.status.idle":"2025-06-16T15:02:35.851168Z","shell.execute_reply.started":"2025-06-16T15:02:35.850961Z","shell.execute_reply":"2025-06-16T15:02:35.850982Z"}},"outputs":[],"execution_count":null}]}